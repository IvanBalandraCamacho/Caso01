# ============================================================================
# LLM PROVIDERS - CONFIGURACIÓN MULTI-MODELO
# ============================================================================

# Proveedor LLM por defecto (usado al iniciar el backend)
# Valores permitidos: "gemini" | "openai"
# Nota: El usuario puede cambiar el modelo desde el frontend durante la sesión
LLM_PROVIDER=gemini

# --- Google Gemini ---
# Obtén tu API key en: https://aistudio.google.com/app/apikey
# Modelo disponible: gemini-2.0-flash-exp (rápido, eficiente, gratuito con límites)
GEMINI_API_KEY=tu-api-key-de-gemini-aqui
GEMINI_MODEL=gemini-2.0-flash-exp

# --- OpenAI ---
# Obtén tu API key en: https://platform.openai.com/api-keys
# Modelo disponible: gpt-4.1-nano-2025-04-14 (compacto, alta calidad)
# OPCIONAL: Deja vacío si solo usarás Gemini
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4.1-nano-2025-04-14

# Configuración adicional de LLM
# (Mantener para compatibilidad, pero LLM_PROVIDER es el valor usado)
ACTIVE_LLM_SERVICE=GEMINI

# ============================================================================
# SEGURIDAD Y AUTENTICACIÓN
# ============================================================================

# JWT Secret Key para firmar tokens
# CRÍTICO: En producción, genera una clave fuerte con:
#   openssl rand -hex 32
# o
#   python -c "import secrets; print(secrets.token_hex(32))"
JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production-use-openssl-rand-hex-32

# Algoritmo de cifrado JWT
JWT_ALGORITHM=HS256

# Tiempo de expiración del token de acceso (en minutos)
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ============================================================================
# NOTAS IMPORTANTES
# ============================================================================
#
# 1. MULTI-LLM:
#    - El sistema precarga ambos providers (Gemini y OpenAI) al iniciar
#    - Los modelos se cachean para evitar re-inicialización
#    - El usuario puede cambiar entre modelos desde el frontend
#    - Cada respuesta incluye un badge mostrando qué modelo se usó
#
# 2. API KEYS:
#    - Gemini: Gratuito con límites (15 RPM, 1M TPM, 1500 RPD)
#    - OpenAI: De pago, consulta precios en platform.openai.com
#
# 3. RENDIMIENTO:
#    - Redis se usa para cache y cola de Celery
#    - Qdrant almacena vectores de documentos procesados
#    - MySQL guarda metadata, conversaciones y mensajes
#
# 4. SEGURIDAD:
#    - NUNCA expongas tus API keys en código o repos públicos
#    - Usa .env solo en desarrollo local
#    - En producción, usa secrets managers (AWS Secrets, Azure Key Vault, etc.)
#    - Genera JWT_SECRET_KEY único por ambiente
#
# ============================================================================

